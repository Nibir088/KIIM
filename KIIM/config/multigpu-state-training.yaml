defaults:
  - _self_  # Changed *self* to _self_ as it's the correct syntax
  
# config_dir: "/project/biocomplexity/wyr6fx(Nibir)/IJCAI-25_Irrigation_Mapping/Pytorch-Lightening/KIIM/config/multigpu-state-training-baseline-Nibir.yaml"

train:
  seed: 88
  # save_dir: "experiments_baseline_CO"
  save_model: true
  max_epochs: 50
  batch_size: 32
  learning_rate: 2e-4
  weight_decay: 1e-4
  early_stopping: true
  patience: 20
  accelerator: "gpu"
  devices: [3]
  strategy: "ddp"
  gradient_clip_val: 1.0
  accumulate_grad_batches: 1
  check_val_every_n_epoch: 1
  precision: 16
  mode: "max"
  monitor: "val_iou_macro"
  verbose: true
  top_k: 1 #how checkpoint value to save
  
dataset:
  data_file_base_name: "/project/biocomplexity/wyr6fx(Nibir)/IJCAI-25_Irrigation_Mapping/Pytorch-Lightening/data-file/dataset_path-AZ-FL-UT-CO-WA.json"
  crop_matrices_path: "/project/biocomplexity/wyr6fx(Nibir)/IJCAI-25_Irrigation_Mapping/Pytorch-Lightening/Data-Collection/matrix"
  data_file_index: "AZ"
  states: ["AZ", "UT", "FL", "CO", "WA"]  # Added quotes for consistency
  image_size: [224, 224]  # Changed tuple notation to list
  transform: false
  gamma_value: 2
  image_types: ["image"]  # Added quotes for consistency
  agri_indices: ["ndvi", "ndti", "ndwi"]  # Added quotes and spaces after commas
  
dataloader:
  batch_size: 32
  num_workers: 4
  pin_memory: true
  
model:
  backbone_name: "unet"
  encoder_name: "resnet50"
  num_classes: 4
  learning_rate: 1e-4
  use_attention: false
  use_projection: false
  use_rgb: true
  use_ndvi: false
  use_ndwi: false
  use_ndti: false
  pretrained_hidden_dim: 16
  attention_hidden_dim: 16
  gamma: 5.0
  weight_decay: 1e-4
  loss_config:
    use_ce: true
    ce_weight: 1.0      # Fixed indentation and removed curly braces
    dice_weight: 0.0
    focal_weight: 0.0
    kg_weight: 0.0
    stream_weight: 0.0
        
logging:
  use_wandb: true
  project_name: "irrigation-segmentation (IJCAI)"
  run_name: result_stats
  save_dir: "logs"
  
finetune:
  checkpoint_path: "experiments/best-model/model.ckpt"  # Path to pretrained model
  strict: false  # Whether to strictly enforce matching keys when loading
  freeze_backbone: false  # Whether to freeze backbone layers
  freeze_encoder: false # Whether to freeze encoder layers
  learning_rate: 1e-5  # Special learning rate for fine-tuning
  
      
hparam_tuning:
  enabled: true  # Set to true to enable hyperparameter tuning
  n_trials: 5   # Number of trials to run
  timeout_hours: 72  # Maximum duration for optimization (optional)
  search_space:
    learning_rate: [1e-4, 2e-4, 1e-3]
    weight_decay:
      min: 1e-6
      max: 1e-4
    dropout_rate:
      min: 0.1
      max: 0.5
    hidden_size:
      min: 32
      max: 32
      step: 0
    num_layers:
      min: 2
      max: 6
    batch_size: [16,32]
      
hydra:
  job:
    chdir: True
  run:
    dir: /project/biocomplexity/wyr6fx(Nibir)/IJCAI-25_Irrigation_Mapping/Pytorch-Lightening/outputs/${dataset.data_file_index}/${now:%Y-%m-%d}/${now:%H-%M-%S}