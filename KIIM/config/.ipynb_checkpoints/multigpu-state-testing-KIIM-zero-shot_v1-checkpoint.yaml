defaults:
  - _self_  # Changed *self* to _self_ as it's the correct syntax
  
# config_dir: "/project/biocomplexity/wyr6fx(Nibir)/IJCAI-25_Irrigation_Mapping/Pytorch-Lightening/KIIM/config/multigpu-state-training-baseline-Nibir.yaml"

train:
  seed: 88
  # save_dir: "experiments_baseline_CO"
  save_model: true
  max_epochs: 50
  batch_size: 32
  # learning_rate: 5e-4
  weight_decay: 1e-4
  early_stopping: true
  patience: 20
  accelerator: "gpu"
  devices: [2]
  strategy: "ddp"
  gradient_clip_val: 1.0
  accumulate_grad_batches: 1
  check_val_every_n_epoch: 1
  precision: 16
  mode: "max"
  monitor: "val_iou_macro"
  verbose: true
  top_k: 1 #how checkpoint value to save
  
dataset:
  data_file_base_name: "/project/biocomplexity/wyr6fx(Nibir)/IJCAI-25_Irrigation_Mapping/Pytorch-Lightening/data-file/dataset_path-AZ-FL-UT-CO-WA-updated.json"
  crop_matrices_path: "/project/biocomplexity/wyr6fx(Nibir)/IJCAI-25_Irrigation_Mapping/Pytorch-Lightening/Data-Collection/matrix"
  data_file_index: "combined_samples_8880_states_wo_FL" #combined_samples_8900_states_all, combined_AZ_UT_WA_UT, combined_samples_8880_states_wo_FL combined_AZ_UT_WA_UT
  states: ["AZ", "UT", "FL", "CO", "WA"]  # Added quotes for consistency
  image_size: [224, 224]  # Changed tuple notation to list
  transform: false
  gamma_value: 2
  image_types: ["image"]  # Added quotes for consistency
  agri_indices: ["ndvi", "ndti", "ndwi"]  # Added quotes and spaces after commas
  
dataloader:
  batch_size: 32
  num_workers: 4
  pin_memory: true
  
model:
  backbone_name: "swin"
  encoder_name: "resnet50"
  num_classes: 4
  learning_rate: 0.0001
  use_attention: true
  use_projection: true
  use_rgb: true
  use_ndvi: true
  use_ndwi: true
  use_ndti: true
  pretrained_hidden_dim: 16
  attention_hidden_dim: 16
  gamma: 0
  weight_decay: 1e-4
  attention_type: "cross"
  loss_config:
    use_ce: false
    ce_weight: 0.0      # Fixed indentation and removed curly braces
    dice_weight: 0.4
    focal_weight: 0.6
    kg_weight: 0.0
    stream_weight: 0.0
test:
    ckpt: /project/biocomplexity/wyr6fx(Nibir)/IJCAI-25_Irrigation_Mapping/Pytorch-Lightening/Experiment_2/without_tuning/KIIM_combined_AZ_UT_WA_UT_v4/result_stats/checkpoints/epoch=70-val_iou_macro=0.940.ckpt
logging:
  use_wandb: false
  project_name: "irrigation-segmentation (IJCAI)"
  run_name: result_stats
  save_dir: "logs"
  
finetune:
  checkpoint_path: "experiments/best-model/model.ckpt"  # Path to pretrained model
  strict: false  # Whether to strictly enforce matching keys when loading
  freeze_backbone: false  # Whether to freeze backbone layers
  freeze_encoder: false # Whether to freeze encoder layers
  learning_rate: 1e-5  # Special learning rate for fine-tuning
  
      
hparam_tuning:
  enabled: true  # Set to true to enable hyperparameter tuning
  n_trials: 5   # Number of trials to run
  timeout_hours: 72  # Maximum duration for optimization (optional)
  search_space:
    learning_rate: [1e-4, 2e-4, 1e-3]
    weight_decay:
      min: 1e-6
      max: 1e-4
    dropout_rate:
      min: 0.1
      max: 0.5
    hidden_size:
      min: 32
      max: 32
      step: 0
    num_layers:
      min: 2
      max: 6
    batch_size: [16,32]
      
hydra:
  job:
    chdir: True
  run:
      # dir: /project/biocomplexity/wyr6fx(Nibir)/IJCAI-25_Irrigation_Mapping/Pytorch-Lightening/temp/test
    # dir: /project/biocomplexity/wyr6fx(Nibir)/IJCAI-25_Irrigation_Mapping/Pytorch-Lightening/Experiment_3/without_tuning/KIIM_${dataset.data_file_index}_v4
    dir: /project/biocomplexity/wyr6fx(Nibir)/IJCAI-25_Irrigation_Mapping/Pytorch-Lightening/Experiment_2/without_tuning/KIIM_combined_AZ_UT_WA_UT_v4
    #/${dataset.data_file_index}/2025-01-29/04-19-06
    # dir: /project/biocomplexity/wyr6fx(Nibir)/IJCAI-25_Irrigation_Mapping/Pytorch-Lightening/temp